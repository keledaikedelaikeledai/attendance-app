name: Deploy to demo via Tailscale

on:
  push:
    branches:
      - master

permissions:
  contents: read

jobs:
  deploy:
    name: Build & deploy to Tailnet host
    runs-on: ubuntu-latest
    environment: demo
    env:
      DEPLOY_ENV: demo
      TARGET_SSH_PORT: 8022
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          version: latest

      - name: Install dependencies
        run: bun install --optional

      - name: Build (Nuxt + Nitro)
        run: bun run build -- --preset bun

      - name: Setup QEMU for cross-platform container support
        uses: docker/setup-qemu-action@v2

      - name: Setup Docker buildx
        uses: docker/setup-buildx-action@v2

      - name: Build runtime artifacts for target arch (linux/arm64) inside container
        run: |
          # Run an arm64 container and perform a Bun install + build inside it so
          # node_modules and .output are produced for the target architecture.
          # Files created will be owned by the runner user via --user.
          set -euo pipefail
          echo "Building runtime artifacts for linux/arm64 inside container"
          docker run --rm --platform linux/arm64 \
            --env HOST_UID="$(id -u)" \
            --env HOST_GID="$(id -g)" \
            -e HOME=/work \
            -v "${PWD}":/work \
            -w /work \
            node:20-bullseye-slim bash -lc '\
              set -euo pipefail; \
              echo "Preparing container: apt-get update && install curl/ca-certificates"; \
              export DEBIAN_FRONTEND=noninteractive; \
              apt-get update -y && apt-get install -y --no-install-recommends curl ca-certificates && rm -rf /var/lib/apt/lists/*; \
              echo "Installing bun into HOME=$HOME"; \
              curl -fsSL https://bun.sh/install | bash; \
              export PATH="$HOME/.bun/bin:$PATH"; \
              bun --version || true; \
              echo "Running bun install (production + optional)"; \
              bun install --production --optional || true; \
              echo "Running bun build"; \
              bun run build -- --preset bun || true; \
              # Ensure files created in /work are owned by the host runner user
              echo "Adjusting ownership of /work to ${HOST_UID:-1000}:${HOST_GID:-1000}"; \
              chown -R "${HOST_UID:-1000}:${HOST_GID:-1000}" /work || true;'

      - name: Prepare deploy archive
        run: |
          # Create a stable snapshot of tracked files (git archive) into a temp dir,
          # then add build/runtime artifacts (.output, public) if present and compress.
          rm -rf deploy_tmp deploy.tar.gz
          mkdir -p deploy_tmp

          # Export tracked files at HEAD to the temp dir
          git archive HEAD | tar -x -C deploy_tmp

          # Copy build artifacts produced by the previous steps (if any)
          if [ -d .output ]; then
            cp -a .output deploy_tmp/.output
          fi
          if [ -d public ]; then
            cp -a public deploy_tmp/public
          fi

          # Include node_modules and any server nested node_modules if present.
          # We built platform-specific node_modules in a cross-arch container earlier
          # so include them in the archive (target won't need to run bun install).
          if [ -d node_modules ]; then
            cp -a node_modules deploy_tmp/node_modules
          fi
          if [ -d .output/server/node_modules ]; then
            mkdir -p deploy_tmp/.output/server
            cp -a .output/server/node_modules deploy_tmp/.output/server/node_modules
          fi

          # Create compressed archive from the stable temp dir
          tar -czf deploy.tar.gz -C deploy_tmp .
          rm -rf deploy_tmp

      - name: Install & start Tailscale
        run: |
          set -euo pipefail
          # Install tailscale binaries
          curl -fsSL https://tailscale.com/install.sh | sh

          # Start tailscaled only if not already running (avoid socket-in-use)
          if [ -S /var/run/tailscale/tailscaled.sock ] || pgrep -x tailscaled >/dev/null 2>&1; then
            echo "tailscaled already running; skipping start"
          else
            echo "Starting tailscaled..."
            sudo tailscaled --tun=userspace-networking &>/tmp/tailscaled.log &
            # wait for the socket or process to show up
            for i in 1 2 3 4 5; do
              if [ -S /var/run/tailscale/tailscaled.sock ] || pgrep -x tailscaled >/dev/null 2>&1; then
                break
              fi
              sleep 1
            done
          fi

          # Try to bring up tailscale using the provided auth key with retries.
          MAX_ATTEMPTS=3
          ATTEMPT=1
          while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
            echo "Attempt $ATTEMPT/$MAX_ATTEMPTS: tailscale up --authkey (non-interactive)"
            if sudo tailscale up --authkey "${TAILSCALE_AUTHKEY}" --hostname "github-runner-${{ github.run_id }}" 2>/tmp/tailscale_up.err; then
              echo "tailscale up succeeded"
              break
            else
              echo "tailscale up failed on attempt $ATTEMPT; dumping stderr (short):"
              tail -n +1 /tmp/tailscale_up.err || true
              if grep -qi "invalid key" /tmp/tailscale_up.err || grep -qi "not valid" /tmp/tailscale_up.err; then
                echo "ERROR: The provided TAILSCALE_AUTHKEY appears invalid or expired. Create a reusable auth key in the Tailscale admin console and add it to GitHub Secrets as TAILSCALE_AUTHKEY." >&2
                # No point retrying invalid key
                break
              fi
              ATTEMPT=$((ATTEMPT+1))
              sleep $((ATTEMPT*2))
            fi
          done

          echo "--- tailscaled log (tail) ---"
          sudo sh -c 'tail -n 200 /tmp/tailscaled.log || true'
          echo "--- tailscale up stderr (tail) ---"
          sudo sh -c 'tail -n 200 /tmp/tailscale_up.err || true'

          echo "--- tailscale status ---"
          sudo tailscale status || true
          echo "--- tailscale ip -4 ---"
          sudo tailscale ip -4 || true

          # If we ended with an 'invalid key' message, exit non-zero
          if grep -qi "invalid key" /tmp/tailscale_up.err || grep -qi "not valid" /tmp/tailscale_up.err; then
            echo "Final error: TAILSCALE_AUTHKEY invalid or rejected. Aborting." >&2
            exit 1
          fi

        env:
          TAILSCALE_AUTHKEY: ${{ secrets.TAILSCALE_AUTHKEY }}

      - name: Configure SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          # disable strict host key checking for CI (optional; consider adding known_hosts)
          printf "Host *\n  StrictHostKeyChecking no\n  UserKnownHostsFile=/dev/null\n" > ~/.ssh/config

      - name: Ensure remote deploy directory exists
        run: |
          # Create a simple home-staging directory on the remote so scp has a parent to write to.
          SSH_PORT="${TARGET_SSH_PORT:-8022}"
          echo "Ensuring remote home-staging directory exists (ssh port: $SSH_PORT)"
          REMOTE_HOME_STAGE='"$HOME"/app/attendance/${DEPLOY_ENV}'

          # Use a straightforward ssh mkdir -p on the remote user's $HOME to avoid touching Termux root
          if ! timeout 60s ssh -vvv -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=20 ${TARGET_SSH_USER}@${TARGET_HOST} "mkdir -p \"\$HOME/app/attendance/${DEPLOY_ENV}\"" 2>/tmp/ssh_mkdir.err; then
            echo "--- SSH mkdir stderr (/tmp/ssh_mkdir.err) ---"
            sed -n '1,200p' /tmp/ssh_mkdir.err || true
            echo "--- end stderr ---"
            echo "ERROR: Failed to create remote home-staging directory. See output above." >&2
            echo "Running SSH diagnostic (whoami, HOME, id, uname) to help debug the remote environment"
            ssh -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=20 ${TARGET_SSH_USER}@${TARGET_HOST} 'whoami; echo HOME="$HOME"; id; uname -a' 2>/tmp/ssh_diag.err || true
            sed -n '1,200p' /tmp/ssh_diag.err || true
            exit 1
          fi

          echo "Remote home-staging directory ensured: \$HOME/app/attendance/${DEPLOY_ENV}"

          # Optionally attempt to create the distro-side directory inside proot (best-effort)
          echo "Attempting to create distro-side target inside proot (if available)"
          ssh -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=20 ${TARGET_SSH_USER}@${TARGET_HOST} "proot-distro login ubuntu -- mkdir -p '/root/app/attendance/${DEPLOY_ENV}'" 2>/tmp/ssh_proot.err || {
            echo "proot mkdir attempt failed (non-fatal). proot stderr:"; sed -n '1,200p' /tmp/ssh_proot.err || true; true
          }
        env:
          TARGET_HOST: ${{ secrets.TARGET_HOST }}
          TARGET_SSH_USER: ${{ secrets.TARGET_SSH_USER }}
          TARGET_DEPLOY_PATH: ${{ secrets.TARGET_DEPLOY_PATH }}

      - name: Verify Tailscale connectivity to target host
        run: |
          # Try a quick non-interactive SSH check to ensure the Tailscale route is available
          SSH_PORT="${TARGET_SSH_PORT:-8022}"
          echo "Raw TARGET_SSH_PORT: '${TARGET_SSH_PORT:-<unset>}'"
          if ssh -p "$SSH_PORT" -o BatchMode=yes -o ConnectTimeout=10 -o StrictHostKeyChecking=no ${TARGET_SSH_USER}@${TARGET_HOST} 'echo ok' 2>/dev/null; then
            echo "Target reachable over Tailscale"
          else
            echo "ERROR: Target ${TARGET_HOST} is not reachable over Tailscale from the runner. Ensure the TAILSCALE_AUTHKEY is valid and the host is online." >&2
            exit 1
          fi
        env:
          TARGET_HOST: ${{ secrets.TARGET_HOST }}
          TARGET_SSH_USER: ${{ secrets.TARGET_SSH_USER }}

      - name: Copy archive to target host over Tailscale
        run: |
          # Always copy the archive into a home-staging directory on the remote (Termux home).
          # The subsequent Extract step runs inside the distro and will copy/move the archive into the distro as needed.
          SSH_PORT="${TARGET_SSH_PORT:-8022}"
          echo "Raw TARGET_SSH_PORT: '${TARGET_SSH_PORT:-<unset>}'"
          # Query the remote user's HOME explicitly to avoid quoting problems
          echo "Querying remote HOME via SSH"
          REMOTE_HOME=$(ssh -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=20 ${TARGET_SSH_USER}@${TARGET_HOST} 'printf "%s" "$HOME"' 2>/tmp/ssh_home.err) || {
            echo "Failed to query remote HOME; ssh stderr:"; sed -n '1,200p' /tmp/ssh_home.err || true
            echo "Cannot proceed without knowing remote HOME" >&2
            exit 1
          }
          echo "Remote HOME: $REMOTE_HOME"

          REMOTE_STAGE_DIR="${REMOTE_HOME}/app/attendance/${DEPLOY_ENV}"
          echo "Ensuring remote staging dir exists: $REMOTE_STAGE_DIR"
          if ! ssh -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=20 ${TARGET_SSH_USER}@${TARGET_HOST} "mkdir -p \"${REMOTE_STAGE_DIR}\"" 2>/tmp/ssh_mkdir_for_scp.err; then
            echo "Failed to create remote staging dir; stderr:"; sed -n '1,200p' /tmp/ssh_mkdir_for_scp.err || true
            exit 1
          fi

          echo "Copying deploy.tar.gz to remote staging: ${REMOTE_STAGE_DIR}/deploy.tar.gz (ssh port: $SSH_PORT)"
          scp -P "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=20 deploy.tar.gz ${TARGET_SSH_USER}@${TARGET_HOST}:"${REMOTE_STAGE_DIR}/deploy.tar.gz" 2>/tmp/scp.err || {
            echo "--- scp stderr ---"
            sed -n '1,200p' /tmp/scp.err || true
            echo "--- end scp stderr ---"
            echo "ERROR: scp failed. Check that the deploy user has a matching public key, the host is reachable over Tailscale, and the remote path is writable." >&2
            exit 1
          }
        env:
          TARGET_HOST: ${{ secrets.TARGET_HOST }}
          TARGET_SSH_USER: ${{ secrets.TARGET_SSH_USER }}
          TARGET_DEPLOY_PATH: ${{ secrets.TARGET_DEPLOY_PATH }}

      - name: Verify uploaded archive exists on target
        run: |
          SSH_PORT="${TARGET_SSH_PORT:-8022}"
          echo "Raw TARGET_SSH_PORT: '${TARGET_SSH_PORT:-<unset>}'"

          # Query remote HOME so we can check a concrete path (matches the copy step behavior)
          REMOTE_HOME=$(ssh -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=20 ${TARGET_SSH_USER}@${TARGET_HOST} 'printf "%s" "$HOME"' 2>/tmp/ssh_home_verify.err) || {
            echo "Failed to determine remote HOME; ssh stderr:"; sed -n '1,200p' /tmp/ssh_home_verify.err || true
            exit 1
          }
          echo "Remote HOME for verify: $REMOTE_HOME"

          CHECK_PATH="${REMOTE_HOME}/app/attendance/${DEPLOY_ENV}/deploy.tar.gz"
          echo "Verifying archive exists at: $CHECK_PATH"

          if ! ssh -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=20 ${TARGET_SSH_USER}@${TARGET_HOST} "[ -f \"${CHECK_PATH}\" ]" 2>/tmp/ssh_verify.err; then
            echo "ERROR: deploy.tar.gz not found on target at ${CHECK_PATH}" >&2
            echo "Remote staging dir listing (for debugging):"
            ssh -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=20 ${TARGET_SSH_USER}@${TARGET_HOST} "ls -la \"${REMOTE_HOME}/app/attendance/${DEPLOY_ENV}\" || true" 2>/tmp/ssh_verify_ls.err || true
            echo "--- ls stderr (if any) ---"
            sed -n '1,200p' /tmp/ssh_verify_ls.err || true
            echo "--- end ls stderr ---"
            cat /tmp/ssh_verify.err || true
            exit 1
          fi
          echo "OK: deploy.tar.gz found at ${CHECK_PATH}"
        env:
          TARGET_HOST: ${{ secrets.TARGET_HOST }}
          TARGET_SSH_USER: ${{ secrets.TARGET_SSH_USER }}
          TARGET_DEPLOY_PATH: ${{ secrets.TARGET_DEPLOY_PATH }}

      - name: Extract, build and start with PM2 on target host
        run: |
          SSH_PORT="${TARGET_SSH_PORT:-8022}"
          echo "About to run remote extract/build/start (ssh port: $SSH_PORT)"
          # Safer approach: render a small proot-runner script on the CI runner (expanding DEPLOY_ENV),
          # scp it into the remote staging dir, then invoke it inside the distro. This avoids nested
          # heredocs and complex printf quoting inside YAML.

          # Query remote HOME so we know where to place the proot runner script
          REMOTE_HOME=$(ssh -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=20 ${TARGET_SSH_USER}@${TARGET_HOST} 'printf "%s" "$HOME"' 2>/tmp/ssh_home_for_proot.err) || {
            echo "Failed to query remote HOME for proot step; ssh stderr:"; sed -n '1,200p' /tmp/ssh_home_for_proot.err || true
            exit 1
          }
          echo "Remote HOME for proot step: $REMOTE_HOME"

          REMOTE_STAGE_DIR="${REMOTE_HOME}/app/attendance/${DEPLOY_ENV}"
          PROOT_SCRIPT_REMOTE="${REMOTE_STAGE_DIR}/proot_deploy_${DEPLOY_ENV}.sh"

          # Create a temporary proot script on the runner. Note: we expand DEPLOY_ENV now, but
          # keep occurrences of $HOME escaped so they resolve on the remote when the script runs.
          # Render a template for the proot deploy script, then substitute DEPLOY_ENV
          # on the runner (so the remote script contains a concrete deploy env value).
          cat > proot_deploy.sh.tmpl <<'TEMPLATE'
          #!/usr/bin/env bash
          set -euo pipefail
          TDIR="/root/app/attendance/__DEPLOY_ENV__"
          if [ ! -d "${TDIR}" ]; then
            echo "PROOT: target directory ${TDIR} not found; nothing to do" >&2
            exit 0
          fi
          cd "${TDIR}" || { echo "PROOT: cannot cd into ${TDIR}" >&2; exit 1; }
          echo "PROOT: operating inside $(pwd)"
          echo "PROOT: listing directory contents (first 50 entries)"
          ls -la | head -n 50 || true

          # Remove any node_modules that may have been bundled on the build runner
          # (these will be for the runner's platform and can break native/optional deps
          # on the target). Reinstall inside the proot environment so platform-specific
          # optional deps (e.g. @libsql/linux-arm64-gnu) are fetched for the target.
          echo "PROOT: cleaning bundled node_modules (if present)"
          rm -rf .output/server/node_modules || true
          rm -rf node_modules || true

          if command -v bun >/dev/null 2>&1; then
            echo "PROOT: running bun install to install deps for target platform"
            # Attempt a fresh install inside the distro. Allow failures to continue
            # gracefully in case bun isn't fully configured; downstream steps will
            # attempt to run the server as best-effort.
            bun install || true

            # Rebuild server output if a build script exists. This is best-effort.
            if [ -f package.json ] && grep -q '"build"' package.json 2>/dev/null; then
              echo "PROOT: running build inside distro"
              bun run build -- --preset bun || true
            fi
          else
            echo "PROOT: bun missing in distro" >&2
          fi

          if command -v pm2 >/dev/null 2>&1; then
            pm2 stop attendance-app || true
            pm2 delete attendance-app || true
            pm2 start --name attendance-app --interpreter "$(command -v bun || true)" ./.output/server/index.mjs --update-env || true
            pm2 save || true
          else
            echo "PROOT: pm2 missing; attempting to run bun directly in background"
            nohup "$(command -v bun || true)" ./.output/server/index.mjs &>/dev/null &
          fi
          TEMPLATE

          # Now substitute placeholders with concrete values on the runner.
          DEPLOY_ENV_VAL="${DEPLOY_ENV:-demo}"
          sed -e "s|__DEPLOY_ENV__|${DEPLOY_ENV_VAL}|g" proot_deploy.sh.tmpl > proot_deploy.sh
          chmod +x proot_deploy.sh
          rm -f proot_deploy.sh.tmpl

          # Ensure the target directory exists inside the proot distro, then stream the archive
          # directly into the distro and execute the proot script via stdin (no scp to Termux).
          echo "Ensuring /root/app/attendance/${DEPLOY_ENV} exists inside proot"
          ssh -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=20 ${TARGET_SSH_USER}@${TARGET_HOST} "proot-distro login ubuntu -- mkdir -p '/root/app/attendance/${DEPLOY_ENV}'" 2>/tmp/ssh_proot_mkdir.err || {
            echo "Failed to create target dir inside proot; stderr:"; sed -n '1,200p' /tmp/ssh_proot_mkdir.err || true
            exit 1
          }

          if [ -f deploy.tar.gz ]; then
            echo "Streaming deploy.tar.gz into proot (/root/app/attendance/${DEPLOY_ENV})"
            ssh -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=120 ${TARGET_SSH_USER}@${TARGET_HOST} "proot-distro login ubuntu -- tar -xzf - -C '/root/app/attendance/${DEPLOY_ENV}'" < deploy.tar.gz 2>/tmp/ssh_stream_tar.err || {
              echo "Failed to stream deploy.tar.gz into proot; stderr:"; sed -n '1,200p' /tmp/ssh_stream_tar.err || true
              exit 1
            }
          else
            echo "Local deploy.tar.gz not found; nothing to stream into proot" >&2
          fi

          echo "Executing proot deploy script inside proot via stdin"
          ssh -p "$SSH_PORT" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=120 ${TARGET_SSH_USER}@${TARGET_HOST} "proot-distro login ubuntu -- bash -s" < proot_deploy.sh 2>/tmp/ssh_proot_run.err || {
            echo "Failed to execute proot script inside distro; stderr:"; sed -n '1,200p' /tmp/ssh_proot_run.err || true
            exit 1
          }

          # local cleanup
          rm -f proot_deploy.sh || true
        env:
          TARGET_HOST: ${{ secrets.TARGET_HOST }}
          TARGET_SSH_USER: ${{ secrets.TARGET_SSH_USER }}
          TARGET_DEPLOY_PATH: ${{ secrets.TARGET_DEPLOY_PATH }}

      - name: Notify
        run: echo "Deploy to ${TARGET_HOST} completed"
        env:
          TARGET_HOST: ${{ secrets.TARGET_HOST }}

      - name: Cleanup Tailscale and runner artifacts
        if: always()
        run: |
          echo "Cleaning up tailscale and temporary files"
          set -euo pipefail
          # Attempt to bring down tailscale and logout (idempotent)
          if command -v tailscale >/dev/null 2>&1; then
            sudo tailscale down || true
            sudo tailscale logout || true
          fi
          # Kill tailscaled if it's still running
          if pgrep -x tailscaled >/dev/null 2>&1; then
            sudo pkill -9 tailscaled || true
          fi
          # Remove tailscaled socket and temp logs we created
          sudo rm -f /var/run/tailscale/tailscaled.sock || true
          sudo rm -f /tmp/tailscaled.log /tmp/tailscale_up.err || true
          # Remove the private key from runner workspace
          rm -f ~/.ssh/id_rsa || true
          # Remove ssh config created earlier
          rm -f ~/.ssh/config || true
          echo "Cleanup finished"
        env:
          TARGET_HOST: ${{ secrets.TARGET_HOST }}

    # required secrets
    # secrets to set in repository settings:
    # - TAILSCALE_AUTHKEY
    # - SSH_PRIVATE_KEY (PEM formatted private key for TARGET_SSH_USER)
    # - TARGET_HOST (target device Tailscale IP or hostname reachable over tailnet)
    # - TARGET_SSH_USER (username to SSH as)
    # - TARGET_DEPLOY_PATH (optional remote path, defaults to /home/<user>/deploy)
